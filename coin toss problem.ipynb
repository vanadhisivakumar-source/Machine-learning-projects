{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNIGyjd4CTtXu5KOGyJFHHI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vanadhisivakumar-source/Machine-learning-projects/blob/main/coin%20toss%20problem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dab95606"
      },
      "source": [
        "# Task\n",
        "Implement the Expectation-Maximization (EM) algorithm to estimate the head probabilities for two coins, Coin A and Coin B, given observed data consisting of the number of heads in several trials. The task involves initializing parameters, iteratively performing E-steps and M-steps until convergence, outputting the final estimated head probabilities for both coins, identifying the most likely coin for each trial, and visualizing the convergence of the estimated probabilities over iterations. Finally, summarize the results and provide insights into the EM algorithm's performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e84d9fb"
      },
      "source": [
        "## Initialize Parameters\n",
        "\n",
        "### Subtask:\n",
        "Define the observed dataset (number of heads for each trial) and make initial guesses for the head probabilities of Coin A and Coin B. Also, define the number of trials and tosses per trial.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0074351"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires defining the observed dataset, initial head probabilities for two coins, and the number of tosses per trial. I will use a code block to initialize these parameters as specified in the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64e4db73"
      },
      "source": [
        "data = [5, 9, 8, 4, 7]\n",
        "p_a = 0.6\n",
        "p_b = 0.4\n",
        "n_tosses = 10\n",
        "\n",
        "print(f\"Observed data (heads per trial): {data}\")\n",
        "print(f\"Initial probability of heads for Coin A (p_a): {p_a}\")\n",
        "print(f\"Initial probability of heads for Coin B (p_b): {p_b}\")\n",
        "print(f\"Number of tosses per trial (n_tosses): {n_tosses}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de485ddc"
      },
      "source": [
        "## Implement EM Algorithm\n",
        "\n",
        "### Subtask:\n",
        "Implement the Expectation-Maximization (EM) algorithm by iteratively performing E-steps and M-steps until the estimated parameters converge. This involves calculating posterior probabilities in the E-step and updating coin probabilities in the M-step.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03ac56e1"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires implementing the EM algorithm by iteratively performing E-steps and M-steps until convergence. This involves importing necessary libraries, defining iteration parameters, calculating posterior probabilities in the E-step, updating coin probabilities in the M-step, and checking for convergence. I will include the existing `p_a`, `p_b`, `data`, and `n_tosses` variables from the previous step.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2d247aa"
      },
      "source": [
        "from scipy.stats import binom\n",
        "\n",
        "# Define EM parameters\n",
        "max_iterations = 100\n",
        "tolerance = 1e-4\n",
        "\n",
        "# History of probabilities for visualization\n",
        "p_a_history = []\n",
        "p_b_history = []\n",
        "\n",
        "print(f\"Starting EM algorithm with initial p_a={p_a:.4f}, p_b={p_b:.4f}\\n\")\n",
        "\n",
        "for i in range(max_iterations):\n",
        "    # E-step (Expectation)\n",
        "    responsibilities_a = []\n",
        "    responsibilities_b = []\n",
        "\n",
        "    for heads_observed in data:\n",
        "        # Likelihood of observing heads_observed given Coin A and Coin B\n",
        "        likelihood_a = binom.pmf(heads_observed, n_tosses, p_a)\n",
        "        likelihood_b = binom.pmf(heads_observed, n_tosses, p_b)\n",
        "\n",
        "        # Denominator for normalization\n",
        "        denominator = likelihood_a + likelihood_b\n",
        "\n",
        "        # Responsibilities (posterior probabilities)\n",
        "        # Avoid division by zero in case both likelihoods are zero (shouldn't happen with valid PMF)\n",
        "        if denominator == 0:\n",
        "            # If both likelihoods are zero, assign equal responsibility or handle as an edge case.\n",
        "            # For this context, assuming valid probabilities leading to non-zero denominators.\n",
        "            resp_a = 0.5\n",
        "            resp_b = 0.5\n",
        "        else:\n",
        "            resp_a = likelihood_a / denominator\n",
        "            resp_b = likelihood_b / denominator\n",
        "\n",
        "        responsibilities_a.append(resp_a)\n",
        "        responsibilities_b.append(resp_b)\n",
        "\n",
        "    # M-step (Maximization)\n",
        "    # Update probabilities based on responsibilities\n",
        "    sum_weighted_heads_a = sum(r_a * h for r_a, h in zip(responsibilities_a, data))\n",
        "    sum_weighted_tosses_a = sum(r_a * n_tosses for r_a in responsibilities_a)\n",
        "\n",
        "    sum_weighted_heads_b = sum(r_b * h for r_b, h in zip(responsibilities_b, data))\n",
        "    sum_weighted_tosses_b = sum(r_b * n_tosses for r_b in responsibilities_b)\n",
        "\n",
        "    # Avoid division by zero if sum_weighted_tosses is zero\n",
        "    new_p_a = sum_weighted_heads_a / sum_weighted_tosses_a if sum_weighted_tosses_a > 0 else p_a\n",
        "    new_p_b = sum_weighted_heads_b / sum_weighted_tosses_b if sum_weighted_tosses_b > 0 else p_b\n",
        "\n",
        "    # Convergence check\n",
        "    diff_a = abs(new_p_a - p_a)\n",
        "    diff_b = abs(new_p_b - p_b)\n",
        "\n",
        "    if diff_a < tolerance and diff_b < tolerance:\n",
        "        print(f\"Converged at iteration {i+1}.\")\n",
        "        break\n",
        "\n",
        "    # Update and history\n",
        "    p_a = new_p_a\n",
        "    p_b = new_p_b\n",
        "    p_a_history.append(p_a)\n",
        "    p_b_history.append(p_b)\n",
        "\n",
        "    print(f\"Iteration {i+1}: p_a={p_a:.4f}, p_b={p_b:.4f}\")\n",
        "\n",
        "print(f\"\\nFinal estimated probabilities: p_a={p_a:.4f}, p_b={p_b:.4f}\")\n",
        "print(f\"Total iterations: {len(p_a_history)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c1d5ac3"
      },
      "source": [
        "## Identify Most Likely Coin for Each Trial\n",
        "\n",
        "### Subtask:\n",
        "Determine which coin (A or B) was most likely used for each observed trial, given the final estimated head probabilities. Calculate the probability of each trial's outcome under both final estimated coin probabilities and assign the coin with the higher probability to that trial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dd34f6f"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the EM algorithm has converged and we have the final estimated probabilities for Coin A and Coin B, the next step is to use these probabilities to determine which coin was most likely responsible for each observed trial. This involves calculating the likelihood of each trial's outcome under both final estimated coin probabilities and then assigning the coin with the higher probability to that trial.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5518d08a"
      },
      "source": [
        "print(f\"\\nIdentifying the most likely coin for each trial using final p_a={p_a:.4f} and p_b={p_b:.4f}:\")\n",
        "\n",
        "most_likely_coins = []\n",
        "\n",
        "for i, heads_observed in enumerate(data):\n",
        "    # Likelihood of observing heads_observed given final p_a\n",
        "    likelihood_a_final = binom.pmf(heads_observed, n_tosses, p_a)\n",
        "\n",
        "    # Likelihood of observing heads_observed given final p_b\n",
        "    likelihood_b_final = binom.pmf(heads_observed, n_tosses, p_b)\n",
        "\n",
        "    if likelihood_a_final > likelihood_b_final:\n",
        "        most_likely_coin = 'Coin A'\n",
        "    elif likelihood_b_final > likelihood_a_final:\n",
        "        most_likely_coin = 'Coin B'\n",
        "    else:\n",
        "        most_likely_coin = 'Equal likelihood' # Should be rare in practice with floating point numbers\n",
        "\n",
        "    most_likely_coins.append(most_likely_coin)\n",
        "    print(f\"Trial {i+1} ({heads_observed} heads): Likelihood A={likelihood_a_final:.4f}, Likelihood B={likelihood_b_final:.4f} -> Most Likely: {most_likely_coin}\")\n",
        "\n",
        "print(f\"\\nMost likely coins for each trial: {most_likely_coins}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fff6e205"
      },
      "source": [
        "## Visualize Convergence\n",
        "\n",
        "### Subtask:\n",
        "Plot the estimated head probabilities for Coin A and Coin B (`p_a_history` and `p_b_history`) against the number of iterations to visualize their convergence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0274b0e1"
      },
      "source": [
        "**Reasoning**:\n",
        "To visualize the convergence of the EM algorithm, I will plot the stored `p_a_history` and `p_b_history` values against the iteration number. This will clearly show how the estimated probabilities changed over time until convergence.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "746d4f09"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, len(p_a_history) + 1), p_a_history, label='Estimated P(Heads | Coin A)', marker='o', linestyle='-')\n",
        "plt.plot(range(1, len(p_b_history) + 1), p_b_history, label='Estimated P(Heads | Coin B)', marker='x', linestyle='--')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Probability of Heads')\n",
        "plt.title('Convergence of Estimated Probabilities (EM Algorithm)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(\"Plot showing the convergence of estimated probabilities generated.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74dc5fc3"
      },
      "source": [
        "## Summarize Results and Provide Insights\n",
        "\n",
        "### Subtask:\n",
        "Summarize the results of the EM algorithm, including the final estimated head probabilities for Coin A and Coin B, the most likely coin assignments for each trial, and insights gained from the convergence plot and the overall algorithm performance.\n",
        "\n",
        "**Summary:**\n",
        "\n",
        "1.  **Initial Parameters:** The algorithm started with `data = [5, 9, 8, 4, 7]` (heads observed in 10 tosses per trial), `p_a = 0.6`, `p_b = 0.4`.\n",
        "\n",
        "2.  **EM Algorithm Convergence:** The EM algorithm converged in 8 iterations (after the first update, as per history length) with a tolerance of `1e-4`.\n",
        "\n",
        "3.  **Final Estimated Probabilities:**\n",
        "    *   Estimated `P(Heads | Coin A) = p_a = 0.7967`\n",
        "    *   Estimated `P(Heads | Coin B) = p_b = 0.5196`\n",
        "\n",
        "4.  **Most Likely Coin Assignments for Each Trial:**\n",
        "    *   Trial 1 (5 heads): Most Likely **Coin B** (Likelihood A=0.0281, Likelihood B=0.2442)\n",
        "    *   Trial 2 (9 heads): Most Likely **Coin A** (Likelihood A=0.2629, Likelihood B=0.0133)\n",
        "    *   Trial 3 (8 heads): Most Likely **Coin A** (Likelihood A=0.3019, Likelihood B=0.0552)\n",
        "    *   Trial 4 (4 heads): Most Likely **Coin B** (Likelihood A=0.0060, Likelihood B=0.1882)\n",
        "    *   Trial 5 (7 heads): Most Likely **Coin A** (Likelihood A=0.2054, Likelihood B=0.1360)\n",
        "\n",
        "    The assignments were `['Coin B', 'Coin A', 'Coin A', 'Coin B', 'Coin A']`.\n",
        "\n",
        "**Insights into EM Algorithm Performance:**\n",
        "\n",
        "*   **Convergence Speed:** The algorithm converged relatively quickly (in 8 iterations), demonstrating its efficiency in finding optimal parameters for this dataset. The convergence plot visually confirms a rapid initial adjustment followed by smaller, fine-tuning steps.\n",
        "*   **Parameter Separation:** The EM algorithm successfully separated the two coin parameters. Coin A's probability (`~0.8`) is significantly higher than Coin B's probability (`~0.5`), indicating that the observed data likely originated from two distinct coin types.\n",
        "*   **Responsibility Assignment:** The E-step effectively assigned responsibilities, allowing the M-step to update the probabilities based on a weighted average of observations. This iterative process gradually refines the parameter estimates.\n",
        "*   **Handling Latent Variables:** This example effectively demonstrates how EM can estimate parameters for a mixture model where the source of each observation (which coin was flipped) is a latent variable. The algorithm infers these latent assignments (implicitly through responsibilities) and the model parameters simultaneously.\n",
        "*   **Robustness:** Even with initial guesses that were not extremely close to the final values (e.g., `p_a=0.6` to `0.7967`), the algorithm successfully found stable and meaningful estimates.\n",
        "\n",
        "Overall, the EM algorithm performed well in estimating the hidden probabilities of the two coins and segmenting the trials based on these estimates."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bda74bff"
      },
      "source": [
        "## Summarize Results and Provide Insights\n",
        "\n",
        "### Subtask:\n",
        "Summarize the results of the EM algorithm, including the final estimated head probabilities for Coin A and Coin B, the most likely coin assignments for each trial, and insights gained from the convergence plot and the overall algorithm performance.\n",
        "\n",
        "**Summary:**\n",
        "\n",
        "1.  **Initial Parameters:** The algorithm started with `data = [5, 9, 8, 4, 7]` (heads observed in 10 tosses per trial), `p_a = 0.6`, `p_b = 0.4`.\n",
        "\n",
        "2.  **EM Algorithm Convergence:** The EM algorithm converged in 8 iterations (after the first update, as per history length) with a tolerance of `1e-4`.\n",
        "\n",
        "3.  **Final Estimated Probabilities:**\n",
        "    *   Estimated `P(Heads | Coin A) = p_a = 0.7967`\n",
        "    *   Estimated `P(Heads | Coin B) = p_b = 0.5196`\n",
        "\n",
        "4.  **Most Likely Coin Assignments for Each Trial:**\n",
        "    *   Trial 1 (5 heads): Most Likely **Coin B** (Likelihood A=0.0281, Likelihood B=0.2442)\n",
        "    *   Trial 2 (9 heads): Most Likely **Coin A** (Likelihood A=0.2629, Likelihood B=0.0133)\n",
        "    *   Trial 3 (8 heads): Most Likely **Coin A** (Likelihood A=0.3019, Likelihood B=0.0552)\n",
        "    *   Trial 4 (4 heads): Most Likely **Coin B** (Likelihood A=0.0060, Likelihood B=0.1882)\n",
        "    *   Trial 5 (7 heads): Most Likely **Coin A** (Likelihood A=0.2054, Likelihood B=0.1360)\n",
        "\n",
        "    The assignments were `['Coin B', 'Coin A', 'Coin A', 'Coin B', 'Coin A']`.\n",
        "\n",
        "**Insights into EM Algorithm Performance:**\n",
        "\n",
        "*   **Convergence Speed:** The algorithm converged relatively quickly (in 8 iterations), demonstrating its efficiency in finding optimal parameters for this dataset. The convergence plot visually confirms a rapid initial adjustment followed by smaller, fine-tuning steps.\n",
        "*   **Parameter Separation:** The EM algorithm successfully separated the two coin parameters. Coin A's probability (`~0.8`) is significantly higher than Coin B's probability (`~0.5`), indicating that the observed data likely originated from two distinct coin types.\n",
        "*   **Responsibility Assignment:** The E-step effectively assigned responsibilities, allowing the M-step to update the probabilities based on a weighted average of observations. This iterative process gradually refines the parameter estimates.\n",
        "*   **Handling Latent Variables:** This example effectively demonstrates how EM can estimate parameters for a mixture model where the source of each observation (which coin was flipped) is a latent variable. The algorithm infers these latent assignments (implicitly through responsibilities) and the model parameters simultaneously.\n",
        "*   **Robustness:** Even with initial guesses that were not extremely close to the final values (e.g., `p_a=0.6` to `0.7967`), the algorithm successfully found stable and meaningful estimates.\n",
        "\n",
        "Overall, the EM algorithm performed well in estimating the hidden probabilities of the two coins and segmenting the trials based on these estimates.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6456f5a5"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "*   **What are the final estimated head probabilities for Coin A and Coin B?**\n",
        "    The final estimated head probability for Coin A ($\\text{p_a}$) is 0.7967, and for Coin B ($\\text{p_b}$) is 0.5196.\n",
        "*   **Which coin is most likely for each trial?**\n",
        "    Based on the final estimated probabilities, the most likely coin assignments for the trials are:\n",
        "    *   Trial 1 (5 heads): Coin B\n",
        "    *   Trial 2 (9 heads): Coin A\n",
        "    *   Trial 3 (8 heads): Coin A\n",
        "    *   Trial 4 (4 heads): Coin B\n",
        "    *   Trial 5 (7 heads): Coin A\n",
        "*   **How did the EM algorithm perform?**\n",
        "    The EM algorithm performed well, converging quickly in 9 iterations (8 updates in history) with a tolerance of $\\text{1e-4}$. It successfully separated the two coin parameters, demonstrated efficiency, and effectively handled latent variables to assign responsibilities and update probabilities.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   The EM algorithm was initialized with an observed dataset of heads per trial: [5, 9, 8, 4, 7], and 10 tosses per trial.\n",
        "*   Initial head probabilities were set to $\\text{p_a} = 0.6$ and $\\text{p_b} = 0.4$.\n",
        "*   The algorithm converged in 9 iterations (8 updates stored in history) using a tolerance of $\\text{1e-4}$.\n",
        "*   The final estimated probabilities are $\\text{P(Heads | Coin A)} = 0.7967$ and $\\text{P(Heads | Coin B)} = 0.5196$.\n",
        "*   The most likely coin assignments for the trials are ['Coin B', 'Coin A', 'Coin A', 'Coin B', 'Coin A'].\n",
        "*   The convergence plot visually confirmed that both $\\text{p_a}$ and $\\text{p_b}$ stabilized quickly, indicating rapid convergence.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The EM algorithm efficiently estimated hidden parameters for a mixture model, even with initial guesses not perfectly aligned with the final values, showcasing its robustness and ability to separate distinct underlying processes.\n",
        "*   The rapid convergence and clear separation of probabilities suggest that the observed data strongly supports the existence of two distinct coin types, one heavily biased towards heads ($\\sim$0.8) and another slightly biased towards heads ($\\sim$0.5).\n"
      ]
    }
  ]
}