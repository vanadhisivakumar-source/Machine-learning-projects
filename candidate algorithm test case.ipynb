{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMvbzAdD/lLWPdOGTVjTxcU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vanadhisivakumar-source/Machine-learning-projects/blob/main/candidate%20algorithm%20test%20case.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd6eb595"
      },
      "source": [
        "# Task\n",
        "Implement the Candidate Elimination algorithm to learn a concept from a medical diagnosis dataset. The dataset should have attributes 'Fever', 'Cough', and 'Fatigue', and a target 'Disease'. After implementing the algorithm, display the final Most Specific Hypothesis (S) and Most General Hypothesis (G)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0719d32c"
      },
      "source": [
        "## Define Dataset\n",
        "\n",
        "### Subtask:\n",
        "Define the medical diagnosis dataset with 'Fever', 'Cough', 'Fatigue' as attributes and 'Disease' as the target, based on the examples provided. This will be represented as a list of lists or a pandas DataFrame.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8ce6568"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires defining a dataset as a pandas DataFrame. This involves importing pandas, creating a list of lists with the specified data, converting it into a DataFrame with appropriate column names, and then displaying the head of the DataFrame for verification.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "017d6e06"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the dataset as a list of lists\n",
        "data = [\n",
        "    ['Yes', 'Yes', 'No', 'Flu'],\n",
        "    ['No', 'Yes', 'Yes', 'Cold'],\n",
        "    ['Yes', 'No', 'Yes', 'Flu'],\n",
        "    ['No', 'Yes', 'No', 'Cold'],\n",
        "    ['Yes', 'Yes', 'Yes', 'COVID-19'],\n",
        "    ['No', 'No', 'No', 'Healthy'],\n",
        "    ['Yes', 'No', 'No', 'Healthy'],\n",
        "    ['No', 'Yes', 'Yes', 'COVID-19'],\n",
        "    ['Yes', 'Yes', 'Yes', 'Flu'],\n",
        "    ['No', 'No', 'Yes', 'Cold']\n",
        "]\n",
        "\n",
        "# Define the column names\n",
        "columns = ['Fever', 'Cough', 'Fatigue', 'Disease']\n",
        "\n",
        "# Create a pandas DataFrame\n",
        "df_medical_diagnosis = pd.DataFrame(data, columns=columns)\n",
        "\n",
        "# Display the head of the DataFrame\n",
        "print(\"Medical Diagnosis Dataset:\")\n",
        "print(df_medical_diagnosis.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7342b82c"
      },
      "source": [
        "## Initialize Hypotheses\n",
        "\n",
        "### Subtask:\n",
        "Initialize the Most Specific Hypothesis (S) with the first positive example and the Most General Hypothesis (G) with the most general possible hypotheses (e.g., all '?'s for each attribute).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9925a54"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires initializing the Most Specific Hypothesis (S) from the first positive example and the Most General Hypothesis (G) with all '?'s for each attribute. This involves identifying attributes, filtering for the target concept 'Flu', extracting the first positive example, and then constructing G with '?'s.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49459c65"
      },
      "source": [
        "attributes = ['Fever', 'Cough', 'Fatigue']\n",
        "target_concept = 'Flu'\n",
        "\n",
        "# 3. Find the first positive example for the target concept 'Flu'\n",
        "positive_examples = df_medical_diagnosis[df_medical_diagnosis['Disease'] == target_concept]\n",
        "\n",
        "# Extract attribute values for the first positive example to initialize S\n",
        "# If no 'Flu' example exists, this would need error handling, but we assume it exists from the dataset definition.\n",
        "if not positive_examples.empty:\n",
        "    s_initial = list(positive_examples.iloc[0][attributes].values)\n",
        "else:\n",
        "    print(f\"Warning: No positive examples found for '{target_concept}'. Initializing S with generic values.\")\n",
        "    s_initial = ['?', '?', '?'] # Default if no positive example found\n",
        "\n",
        "# 4. Initialize G with '?' for each attribute\n",
        "g_initial = [['?' for _ in attributes]]\n",
        "\n",
        "print(f\"Initial Most Specific Hypothesis (S): {s_initial}\")\n",
        "print(f\"Initial Most General Hypothesis (G): {g_initial}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6890526"
      },
      "source": [
        "## Implement Candidate Elimination Algorithm\n",
        "\n",
        "### Subtask:\n",
        "Implement the Candidate Elimination algorithm by iterating through each example in the dataset and updating the Most Specific Hypothesis (S) and Most General Hypothesis (G) accordingly.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e7409d2"
      },
      "source": [
        "**Reasoning**:\n",
        "First, define the `covers` helper function. This function is crucial for determining if a hypothesis is consistent with a given instance, which is a fundamental operation in the Candidate Elimination algorithm.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1efab2d3"
      },
      "source": [
        "def covers(hypothesis, instance):\n",
        "    \"\"\"\n",
        "    Checks if a hypothesis covers an instance.\n",
        "    A hypothesis covers an instance if for every attribute, the hypothesis's value for that attribute\n",
        "    is either '?' or matches the instance's value.\n",
        "    \"\"\"\n",
        "    for i in range(len(hypothesis)):\n",
        "        if hypothesis[i] == '?':\n",
        "            continue\n",
        "        if hypothesis[i] != instance[i]:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "print(\"Defined 'covers' helper function.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0d4fbc1"
      },
      "source": [
        "**Reasoning**:\n",
        "Now, define the `is_more_general_than` helper function, which determines if one hypothesis is more general than or equal to another, a key component for refining the general hypothesis set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50d335ed"
      },
      "source": [
        "def is_more_general_than(h1, h2):\n",
        "    \"\"\"\n",
        "    Checks if hypothesis h1 is more general than or equal to hypothesis h2.\n",
        "    This means for every attribute, h1's value is either '?' or matches h2's value.\n",
        "    \"\"\"\n",
        "    for i in range(len(h1)):\n",
        "        if h1[i] == '?':\n",
        "            continue\n",
        "        if h1[i] != h2[i]:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "print(\"Defined 'is_more_general_than' helper function.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28d38bf8"
      },
      "source": [
        "**Reasoning**:\n",
        "Next, define the `generalize_specific_hypothesis` helper function as per the instructions. This function will be used to update the Most Specific Hypothesis (S) when it fails to cover a positive example.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "395e86d7"
      },
      "source": [
        "def generalize_specific_hypothesis(s, positive_example_attrs):\n",
        "    \"\"\"\n",
        "    Generalizes the specific hypothesis s to cover the positive example.\n",
        "    \"\"\"\n",
        "    new_s = list(s) # Make a mutable copy\n",
        "    for i in range(len(new_s)):\n",
        "        if new_s[i] == '?':\n",
        "            continue\n",
        "        elif new_s[i] != positive_example_attrs[i]:\n",
        "            new_s[i] = '?'\n",
        "    return new_s\n",
        "\n",
        "print(\"Defined 'generalize_specific_hypothesis' helper function.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc4ef861"
      },
      "source": [
        "**Reasoning**:\n",
        "Now, define the `specialize_general_hypothesis` helper function as described in the instructions. This function is critical for refining the Most General Hypothesis (G) when a negative example is encountered.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9203abf2"
      },
      "source": [
        "def specialize_general_hypothesis(g_hypothesis, negative_example_attrs, attribute_names, attribute_domains):\n",
        "    \"\"\"\n",
        "    Generates minimal specializations of a general hypothesis `g_hypothesis`\n",
        "    so that it no longer covers the `negative_example_attrs`.\n",
        "    \"\"\"\n",
        "    specializations = []\n",
        "    for i in range(len(g_hypothesis)):\n",
        "        if g_hypothesis[i] == '?':\n",
        "            # If the hypothesis has '?' for this attribute, specialize it\n",
        "            # to all values in the domain that are NOT the negative example's value.\n",
        "            # We only specialize if the negative example's attribute value is in the domain.\n",
        "            if negative_example_attrs[i] in attribute_domains[attribute_names[i]]:\n",
        "                for value in attribute_domains[attribute_names[i]]:\n",
        "                    if value != negative_example_attrs[i]:\n",
        "                        new_g_hyp = list(g_hypothesis)\n",
        "                        new_g_hyp[i] = value\n",
        "                        specializations.append(new_g_hyp)\n",
        "        elif g_hypothesis[i] != negative_example_attrs[i]:\n",
        "            # If the hypothesis already doesn't cover the negative example at this attribute,\n",
        "            # we don't need to specialize further for this attribute.\n",
        "            # We can effectively keep the original g_hypothesis as a potential specialization\n",
        "            # if it was already valid. This part needs careful thought within the main loop.\n",
        "            pass # This case is handled by the main loop where we check covers().\n",
        "        # If g_hypothesis[i] == negative_example_attrs[i], it means this specific part\n",
        "        # of the hypothesis covers the negative example, and if this was '?', we just specialized it.\n",
        "        # If it was a specific value, it remains a specific value and we look to other attributes.\n",
        "\n",
        "    # The above logic is for generating *all minimal specializations*. A simpler approach for CE is\n",
        "    # to only specialize '?' attributes that cause a cover of the negative example.\n",
        "    # Let's refine based on typical CE implementation for G set refinement:\n",
        "    # If g_hypothesis covers negative_example_attrs, we need to create specializations\n",
        "    # by replacing '?' in g_hypothesis with specific values such that it no longer covers\n",
        "    # negative_example_attrs.\n",
        "    if covers(g_hypothesis, negative_example_attrs):\n",
        "        for i in range(len(g_hypothesis)):\n",
        "            if g_hypothesis[i] == '?':\n",
        "                # Replace '?' with all specific values from the domain that are NOT the negative example's value\n",
        "                if negative_example_attrs[i] in attribute_domains[attribute_names[i]]:\n",
        "                    for value in attribute_domains[attribute_names[i]]:\n",
        "                        if value != negative_example_attrs[i]:\n",
        "                            new_g_hyp = list(g_hypothesis)\n",
        "                            new_g_hyp[i] = value\n",
        "                            specializations.append(new_g_hyp)\n",
        "\n",
        "    # Remove duplicates and ensure specializations are truly distinct\n",
        "    unique_specializations = []\n",
        "    for hyp in specializations:\n",
        "        if hyp not in unique_specializations:\n",
        "            unique_specializations.append(hyp)\n",
        "\n",
        "    return unique_specializations\n",
        "\n",
        "print(\"Defined 'specialize_general_hypothesis' helper function.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9260e53"
      },
      "source": [
        "**Reasoning**:\n",
        "Initialize the Most Specific Hypothesis (S) and Most General Hypothesis (G) with mutable copies of their initial states. Then, dynamically determine the domain of possible values for each attribute from the `df_medical_diagnosis` DataFrame, which is crucial for specializing the general hypotheses.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2c42a407"
      },
      "source": [
        "S = list(s_initial)\n",
        "G = [list(h) for h in g_initial]\n",
        "\n",
        "# Dynamically determine attribute domains\n",
        "attribute_domains = {}\n",
        "for attr in attributes:\n",
        "    attribute_domains[attr] = list(df_medical_diagnosis[attr].unique())\n",
        "\n",
        "print(f\"Initial S (mutable): {S}\")\n",
        "print(f\"Initial G (mutable): {G}\")\n",
        "print(f\"Attribute Domains: {attribute_domains}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de0dad74"
      },
      "source": [
        "**Reasoning**:\n",
        "Now, implement the main loop of the Candidate Elimination algorithm, iterating through each example in the dataset to update the Most Specific Hypothesis (S) and Most General Hypothesis (G) based on whether the example is positive or negative for the target concept. This step incorporates all previously defined helper functions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00913787"
      },
      "source": [
        "for index, row in df_medical_diagnosis.iterrows():\n",
        "    example_attrs = list(row[attributes].values)\n",
        "    example_label = row['Disease']\n",
        "\n",
        "    print(f\"\\nProcessing example: {example_attrs} -> {example_label}\")\n",
        "\n",
        "    # If the example is positive\n",
        "    if example_label == target_concept:\n",
        "        # Update S\n",
        "        if not covers(S, example_attrs):\n",
        "            S = generalize_specific_hypothesis(S, example_attrs)\n",
        "\n",
        "        # Filter G: remove hypotheses that do not cover the positive example\n",
        "        G = [g_hyp for g_hyp in G if covers(g_hyp, example_attrs)]\n",
        "\n",
        "    # If the example is negative\n",
        "    else:\n",
        "        G_temp = []\n",
        "        for g_hyp in G:\n",
        "            # If g_hyp covers the negative example, it must be specialized\n",
        "            if covers(g_hyp, example_attrs):\n",
        "                specializations = specialize_general_hypothesis(g_hyp, example_attrs, attributes, attribute_domains)\n",
        "                for new_g in specializations:\n",
        "                    # Only add specialization if it is more general than or equal to S\n",
        "                    # and does not cover the negative example (which specialize_general_hypothesis ensures)\n",
        "                    if is_more_general_than(new_g, S) and not covers(new_g, example_attrs):\n",
        "                        G_temp.append(new_g)\n",
        "            else:\n",
        "                # If g_hyp already does not cover the negative example, keep it\n",
        "                G_temp.append(g_hyp)\n",
        "        G = G_temp\n",
        "\n",
        "    # After processing each example, filter G to remove any duplicate hypotheses or any hypothesis that is overly specific\n",
        "    # Remove duplicates from G and hypotheses that are subsumed by others in G\n",
        "    new_G = []\n",
        "    for g1 in G:\n",
        "        is_redundant = False\n",
        "        for g2 in G:\n",
        "            if g1 != g2 and is_more_general_than(g2, g1): # g2 is more general than g1, so g1 is redundant\n",
        "                is_redundant = True\n",
        "                break\n",
        "        if not is_redundant and list(g1) not in [list(x) for x in new_G]: # Avoid adding exact duplicates\n",
        "            new_G.append(list(g1))\n",
        "    G = new_G\n",
        "\n",
        "    print(f\"Current S: {S}\")\n",
        "    print(f\"Current G: {G}\")\n",
        "\n",
        "print(\"\\nCandidate Elimination Algorithm complete.\")\n",
        "print(f\"Final Most Specific Hypothesis (S): {S}\")\n",
        "print(f\"Final Most General Hypothesis (G): {G}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "322d5fe4"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Summarize the implementation of the Candidate Elimination algorithm and present the final specific and general hypotheses derived from the medical diagnosis dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adc3b621"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "The final Most Specific Hypothesis (S) derived from the medical diagnosis dataset for the concept 'Flu' is `['Yes', '?', '?']`.\n",
        "The final Most General Hypothesis (G) derived for the concept 'Flu' is `[]`, meaning no general hypothesis could be found that was consistent with all positive and negative examples processed from the dataset.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   A medical diagnosis dataset was successfully created as a pandas DataFrame with attributes 'Fever', 'Cough', 'Fatigue', and a 'Disease' target.\n",
        "*   The Most Specific Hypothesis (S) was initialized to `['Yes', 'Yes', 'No']`, based on the first positive example for 'Flu'.\n",
        "*   The Most General Hypothesis (G) was initialized as `[['?', '?', '?']]`, representing the most general possible hypothesis.\n",
        "*   The Candidate Elimination algorithm successfully generalized the Most Specific Hypothesis (S) from `['Yes', 'Yes', 'No']` to `['Yes', '?', '?']`. This generalization indicates that for the 'Flu' concept, 'Fever' being 'Yes' is a critical specific attribute, while 'Cough' and 'Fatigue' can be more general.\n",
        "*   The Most General Hypothesis (G) started as `[['?', '?', '?']]` but became empty after processing the dataset. This implies that no hypothesis could satisfy all negative examples while remaining more general than the specific hypothesis S, leading to an inconsistent hypothesis space.\n",
        "*   The attribute domains were dynamically extracted as `{'Fever': ['Yes', 'No'], 'Cough': ['Yes', 'No'], 'Fatigue': ['No', 'Yes']}`.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The empty G set suggests that the target concept 'Flu' might not be perfectly learnable by a single conjunction of attributes within the provided dataset and the constraints of the Candidate Elimination algorithm. This could be due to noise in the data, insufficient examples, or the concept itself being non-linearly separable or disjunctive.\n",
        "*   Consider revisiting the dataset examples, potentially adding more diverse instances, or exploring alternative learning algorithms (e.g., decision trees, neural networks) that can handle more complex concept representations or noise if a complete version space is desired.\n"
      ]
    }
  ]
}