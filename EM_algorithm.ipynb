{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyM/+fku6+u5p3qEPyY/SSXZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vanadhisivakumar-source/Machine-learning-projects/blob/main/EM_algorithm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97zd2GXdd4Pg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57f61510"
      },
      "source": [
        "### Expectation-Maximization (EM) Algorithm for Clustering\n",
        "\n",
        "The EM algorithm is an iterative approach used to find maximum likelihood estimates of parameters in statistical models, particularly when the model depends on unobserved latent variables. In clustering, it's often used with Gaussian Mixture Models (GMMs) to identify underlying Gaussian distributions within the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b52cb011"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.mixture import GaussianMixture\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_blobs # To generate synthetic data\n",
        "\n",
        "# 1. Generate Synthetic Data\n",
        "# Let's create a dataset with 3 distinct clusters (blobs)\n",
        "X, y = make_blobs(n_samples=300, centers=3, cluster_std=0.8, random_state=42)\n",
        "\n",
        "print(\"Generated Synthetic Data (first 5 rows):\\n\", X[:5])\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X[:, 0], X[:, 1], s=50, alpha=0.7)\n",
        "plt.title('Synthetic Data for EM Clustering')\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# 2. Implement the EM Algorithm using GaussianMixture\n",
        "# Initialize a GaussianMixture model with 3 components (clusters)\n",
        "gmm = GaussianMixture(n_components=3, random_state=42)\n",
        "\n",
        "# Fit the model to the data\n",
        "gmm.fit(X)\n",
        "\n",
        "# Predict the cluster assignments for each data point\n",
        "em_predictions = gmm.predict(X)\n",
        "\n",
        "print(\"\\nEM Predictions (first 5):\\n\", em_predictions[:5])\n",
        "print(\"\\nMean of each Gaussian component:\\n\", gmm.means_)\n",
        "print(\"\\nCovariance of each Gaussian component:\\n\", gmm.covariances_)\n",
        "\n",
        "# 3. Visualize the EM Clustering Results\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X[:, 0], X[:, 1], c=em_predictions, s=50, cmap='viridis', alpha=0.7)\n",
        "plt.scatter(gmm.means_[:, 0], gmm.means_[:, 1], marker='X', s=200, color='red', label='Cluster Centers')\n",
        "plt.title('EM Clustering Results (Gaussian Mixture Model)')\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}